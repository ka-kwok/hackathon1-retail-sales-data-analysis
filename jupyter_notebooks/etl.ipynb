{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Hackathon 1 Retail Data Analytics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 1: ETL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "In this section, the aim is to prepare a cleaned dataset for visualization and analysis from the raw data files. There are ETL procedures form data extraction, data cleaning and processing to data load.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Datasets used for this analysis is the retail data set from Kaggle (https://www.kaggle.com/datasets/manjeetsingh/retaildataset). \n",
        "\n",
        "* 3 raw files will be used.\n",
        "    *[stores-dataset.csv](../dataset/raw/stores-dataset.csv) \n",
        "    *[sales-dataset.csv](../dataset//raw/sales-dataset.csv) \n",
        "    *[feature-dataset.csv](../dataset/raw/features-dataset.csv)\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* A cleaned dataset will be save as a CSV file below\n",
        "    *  [retail_cleaned.csv](../dataset/processed/cleaned-dataset.csv)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/denniskwok/Documents/data-analytics/hackathon1-retail-sales-data-analysis/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/denniskwok/Documents/data-analytics/hackathon1-retail-sales-data-analysis'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Part A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded dataset/raw/sales-dataset.csv successfully.\n",
            "Loaded dataset/raw/stores-dataset.csv successfully.\n",
            "Loaded dataset/raw/features-dataset.csv successfully.\n"
          ]
        }
      ],
      "source": [
        "# Load datasets from csv files\n",
        "def load_csv(filepath):\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        print(f\"Loaded {filepath} successfully.\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {filepath}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "df_sales = load_csv(\"dataset/raw/sales-dataset.csv\")\n",
        "df_stores = load_csv(\"dataset/raw/stores-dataset.csv\")\n",
        "df_features = load_csv(\"dataset/raw/features-dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Store         421570 non-null  int64  \n",
            " 1   Dept          421570 non-null  int64  \n",
            " 2   Date          421570 non-null  object \n",
            " 3   Weekly_Sales  421570 non-null  float64\n",
            " 4   IsHoliday     421570 non-null  bool   \n",
            "dtypes: bool(1), float64(1), int64(2), object(1)\n",
            "memory usage: 13.3+ MB\n"
          ]
        }
      ],
      "source": [
        "df_sales.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45 entries, 0 to 44\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Store   45 non-null     int64 \n",
            " 1   Type    45 non-null     object\n",
            " 2   Size    45 non-null     int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.2+ KB\n"
          ]
        }
      ],
      "source": [
        "df_stores.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8190 entries, 0 to 8189\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Store         8190 non-null   int64  \n",
            " 1   Date          8190 non-null   object \n",
            " 2   Temperature   8190 non-null   float64\n",
            " 3   Fuel_Price    8190 non-null   float64\n",
            " 4   MarkDown1     4032 non-null   float64\n",
            " 5   MarkDown2     2921 non-null   float64\n",
            " 6   MarkDown3     3613 non-null   float64\n",
            " 7   MarkDown4     3464 non-null   float64\n",
            " 8   MarkDown5     4050 non-null   float64\n",
            " 9   CPI           7605 non-null   float64\n",
            " 10  Unemployment  7605 non-null   float64\n",
            " 11  IsHoliday     8190 non-null   bool   \n",
            "dtypes: bool(1), float64(9), int64(1), object(1)\n",
            "memory usage: 712.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df_features.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Part B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Transformation (data cleaning and processing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert 'Date' columns to datetime with function convert_date\n",
        "def convert_date(df, col='Date'):\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_datetime(df[col], dayfirst=True)\n",
        "    return df\n",
        "\n",
        "df_sales = convert_date(df_sales)\n",
        "df_features = convert_date(df_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge datasets\n",
        "df_sales_store = pd.merge(df_sales, df_stores, how='left', on='Store')\n",
        "df_merged = pd.merge(df_sales_store, df_features, how='left', on=['Store', 'Date'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* 3 datasets are merged as df_merged and ready for cleaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of         Store  Dept       Date  Weekly_Sales  IsHoliday_x Type    Size  \\\n",
              "0           1     1 2010-02-05      24924.50        False    A  151315   \n",
              "1           1     1 2010-02-12      46039.49         True    A  151315   \n",
              "2           1     1 2010-02-19      41595.55        False    A  151315   \n",
              "3           1     1 2010-02-26      19403.54        False    A  151315   \n",
              "4           1     1 2010-03-05      21827.90        False    A  151315   \n",
              "...       ...   ...        ...           ...          ...  ...     ...   \n",
              "421565     45    98 2012-09-28        508.37        False    B  118221   \n",
              "421566     45    98 2012-10-05        628.10        False    B  118221   \n",
              "421567     45    98 2012-10-12       1061.02        False    B  118221   \n",
              "421568     45    98 2012-10-19        760.01        False    B  118221   \n",
              "421569     45    98 2012-10-26       1076.80        False    B  118221   \n",
              "\n",
              "        Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  \\\n",
              "0             42.31       2.572        NaN        NaN        NaN        NaN   \n",
              "1             38.51       2.548        NaN        NaN        NaN        NaN   \n",
              "2             39.93       2.514        NaN        NaN        NaN        NaN   \n",
              "3             46.63       2.561        NaN        NaN        NaN        NaN   \n",
              "4             46.50       2.625        NaN        NaN        NaN        NaN   \n",
              "...             ...         ...        ...        ...        ...        ...   \n",
              "421565        64.88       3.997    4556.61      20.64       1.50    1601.01   \n",
              "421566        64.89       3.985    5046.74        NaN      18.82    2253.43   \n",
              "421567        54.47       4.000    1956.28        NaN       7.89     599.32   \n",
              "421568        56.47       3.969    2004.02        NaN       3.18     437.73   \n",
              "421569        58.85       3.882    4018.91      58.08     100.00     211.94   \n",
              "\n",
              "        MarkDown5         CPI  Unemployment  IsHoliday_y  \n",
              "0             NaN  211.096358         8.106        False  \n",
              "1             NaN  211.242170         8.106         True  \n",
              "2             NaN  211.289143         8.106        False  \n",
              "3             NaN  211.319643         8.106        False  \n",
              "4             NaN  211.350143         8.106        False  \n",
              "...           ...         ...           ...          ...  \n",
              "421565    3288.25  192.013558         8.684        False  \n",
              "421566    2340.01  192.170412         8.667        False  \n",
              "421567    3990.54  192.327265         8.667        False  \n",
              "421568    1537.49  192.330854         8.667        False  \n",
              "421569     858.33  192.308899         8.667        False  \n",
              "\n",
              "[421570 rows x 17 columns]>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Overview the merged DataFrame\n",
        "df_merged.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 17 columns):\n",
            " #   Column        Non-Null Count   Dtype         \n",
            "---  ------        --------------   -----         \n",
            " 0   Store         421570 non-null  int64         \n",
            " 1   Dept          421570 non-null  int64         \n",
            " 2   Date          421570 non-null  datetime64[ns]\n",
            " 3   Weekly_Sales  421570 non-null  float64       \n",
            " 4   IsHoliday_x   421570 non-null  bool          \n",
            " 5   Type          421570 non-null  object        \n",
            " 6   Size          421570 non-null  int64         \n",
            " 7   Temperature   421570 non-null  float64       \n",
            " 8   Fuel_Price    421570 non-null  float64       \n",
            " 9   MarkDown1     150681 non-null  float64       \n",
            " 10  MarkDown2     111248 non-null  float64       \n",
            " 11  MarkDown3     137091 non-null  float64       \n",
            " 12  MarkDown4     134967 non-null  float64       \n",
            " 13  MarkDown5     151432 non-null  float64       \n",
            " 14  CPI           421570 non-null  float64       \n",
            " 15  Unemployment  421570 non-null  float64       \n",
            " 16  IsHoliday_y   421570 non-null  bool          \n",
            "dtypes: bool(2), datetime64[ns](1), float64(10), int64(3), object(1)\n",
            "memory usage: 49.0+ MB\n"
          ]
        }
      ],
      "source": [
        "# Check the columns details\n",
        "df_merged.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Store                0\n",
              "Dept                 0\n",
              "Date                 0\n",
              "Weekly_Sales         0\n",
              "IsHoliday_x          0\n",
              "Type                 0\n",
              "Size                 0\n",
              "Temperature          0\n",
              "Fuel_Price           0\n",
              "MarkDown1       270889\n",
              "MarkDown2       310322\n",
              "MarkDown3       284479\n",
              "MarkDown4       286603\n",
              "MarkDown5       270138\n",
              "CPI                  0\n",
              "Unemployment         0\n",
              "IsHoliday_y          0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check missing values in the merged DataFrame\n",
        "df_merged.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In the merged dataframe, there are 2 issues to be resolved with data cleaning and processing.\n",
        "    * Duplicated columns: 'IsHoliday_x', 'IsHoliday_y'\n",
        "    * Missing values: 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'\n",
        "    * Change object and bool type to numeric for better visualization and anaylsis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up duplicate columns if they are identical\n",
        "if 'IsHoliday_x' in df_merged.columns and 'IsHoliday_y' in df_merged.columns:\n",
        "    if (df_merged['IsHoliday_x'] == df_merged['IsHoliday_y']).all():\n",
        "        df_merged.drop(columns=['IsHoliday_y'], inplace=True)\n",
        "        df_merged.rename(columns={'IsHoliday_x': 'IsHoliday'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing MarkDown values with 0\n",
        "markdown_cols = [col for col in df_merged.columns if col.startswith('MarkDown')]\n",
        "df_merged[markdown_cols] = df_merged[markdown_cols].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert boolean columns to integers (True=1, False=0)\n",
        "bool_cols = df_merged.select_dtypes(include=['bool']).columns\n",
        "df_merged[bool_cols] = df_merged[bool_cols].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/denniskwok/Documents/data-analytics/hackathon1-retail-sales-data-analysis/.venv/lib/python3.12/site-packages/feature_engine/encoding/base_encoder.py:223: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
            "  if pd.api.types.is_categorical_dtype(X[feature]):\n"
          ]
        }
      ],
      "source": [
        "# Convert column 'Type' to ordinal encoding with pipeline \n",
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine.imputation import DropMissingData\n",
        "\n",
        "pipeline = Pipeline([\n",
        "      ('drop_missing', DropMissingData()), # in case there are missing values\n",
        "      ('ordinal_encoder', OrdinalEncoder(encoding_method='arbitrary', variables=['Type'])) # convert 'Type' column to ordinal encoding\n",
        "])\n",
        "\n",
        "df_merged = pipeline.fit_transform(df_merged)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Load (creating a cleaned dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Store           0\n",
              "Dept            0\n",
              "Date            0\n",
              "Weekly_Sales    0\n",
              "IsHoliday       0\n",
              "Type            0\n",
              "Size            0\n",
              "Temperature     0\n",
              "Fuel_Price      0\n",
              "MarkDown1       0\n",
              "MarkDown2       0\n",
              "MarkDown3       0\n",
              "MarkDown4       0\n",
              "MarkDown5       0\n",
              "CPI             0\n",
              "Unemployment    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#final check for missing values after feature-engineering\n",
        "df_merged.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Store</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151315</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-12</td>\n",
              "      <td>46039.49</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>151315</td>\n",
              "      <td>38.51</td>\n",
              "      <td>2.548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.242170</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>41595.55</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151315</td>\n",
              "      <td>39.93</td>\n",
              "      <td>2.514</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.289143</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-26</td>\n",
              "      <td>19403.54</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151315</td>\n",
              "      <td>46.63</td>\n",
              "      <td>2.561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.319643</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-05</td>\n",
              "      <td>21827.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151315</td>\n",
              "      <td>46.50</td>\n",
              "      <td>2.625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.350143</td>\n",
              "      <td>8.106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Store  Dept       Date  Weekly_Sales  IsHoliday  Type    Size  Temperature  \\\n",
              "0      1     1 2010-02-05      24924.50          0     0  151315        42.31   \n",
              "1      1     1 2010-02-12      46039.49          1     0  151315        38.51   \n",
              "2      1     1 2010-02-19      41595.55          0     0  151315        39.93   \n",
              "3      1     1 2010-02-26      19403.54          0     0  151315        46.63   \n",
              "4      1     1 2010-03-05      21827.90          0     0  151315        46.50   \n",
              "\n",
              "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
              "0       2.572        0.0        0.0        0.0        0.0        0.0   \n",
              "1       2.548        0.0        0.0        0.0        0.0        0.0   \n",
              "2       2.514        0.0        0.0        0.0        0.0        0.0   \n",
              "3       2.561        0.0        0.0        0.0        0.0        0.0   \n",
              "4       2.625        0.0        0.0        0.0        0.0        0.0   \n",
              "\n",
              "          CPI  Unemployment  \n",
              "0  211.096358         8.106  \n",
              "1  211.242170         8.106  \n",
              "2  211.289143         8.106  \n",
              "3  211.319643         8.106  \n",
              "4  211.350143         8.106  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 16 columns):\n",
            " #   Column        Non-Null Count   Dtype         \n",
            "---  ------        --------------   -----         \n",
            " 0   Store         421570 non-null  int64         \n",
            " 1   Dept          421570 non-null  int64         \n",
            " 2   Date          421570 non-null  datetime64[ns]\n",
            " 3   Weekly_Sales  421570 non-null  float64       \n",
            " 4   IsHoliday     421570 non-null  int64         \n",
            " 5   Type          421570 non-null  int64         \n",
            " 6   Size          421570 non-null  int64         \n",
            " 7   Temperature   421570 non-null  float64       \n",
            " 8   Fuel_Price    421570 non-null  float64       \n",
            " 9   MarkDown1     421570 non-null  float64       \n",
            " 10  MarkDown2     421570 non-null  float64       \n",
            " 11  MarkDown3     421570 non-null  float64       \n",
            " 12  MarkDown4     421570 non-null  float64       \n",
            " 13  MarkDown5     421570 non-null  float64       \n",
            " 14  CPI           421570 non-null  float64       \n",
            " 15  Unemployment  421570 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(10), int64(5)\n",
            "memory usage: 51.5 MB\n"
          ]
        }
      ],
      "source": [
        "# Show head and info for final merged dataframe\n",
        "display(df_merged.head())\n",
        "df_merged.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The dataset looks cleaned and ready for further data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned data exported to dataset/processed/retail_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "# Export the cleaned dataframe to a CSV file in the folder for processed CSV\n",
        "df_cleaned = df_merged.copy()\n",
        "df_cleaned.to_csv('dataset/processed/retail_cleaned.csv', index=False)\n",
        "print(f'Cleaned data exported to dataset/processed/retail_cleaned.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To be contined in Section 2 Data Visualization."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
